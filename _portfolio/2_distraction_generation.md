---
title: "Distraction Generation Using T5"
excerpt: "In this paper we generate distract answers for multiple-choice questions given a reference text,
question, and the correct answer. We fine tune a transformer (T5) on the distraction generation task with an additional term in the loss function to penalize distractors similar to the correct answer."
collection: portfolio
citation: "Fernando Gonzalez and Kevin Golan"
venue: 'Final project, Natural Language Procesing @ ETH Zurich'
date: 2020-07-01
paperurl: http://feradauto.github.io/files/distraction_generation.pdf
code: https://github.com/feradauto/distraction_generation
---